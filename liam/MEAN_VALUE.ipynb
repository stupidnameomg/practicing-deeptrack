{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stupidnameomg/practicing-deeptrack/blob/main/liam/MEAN_VALUE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXRzLVLHMGa1",
        "outputId": "5f1ae07b-c2f4-432d-f255-fba40d859d59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deeptrack==0.11.3\n",
            "  Downloading deeptrack-0.11.3-py3-none-any.whl (80 kB)\n",
            "\u001b[K     |████████████████████████████████| 80 kB 3.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from deeptrack==0.11.3) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from deeptrack==0.11.3) (1.19.5)\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.15.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 30.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from deeptrack==0.11.3) (2.7.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deeptrack==0.11.3) (1.6.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deeptrack==0.11.3) (1.43.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deeptrack==0.11.3) (2.7.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deeptrack==0.11.3) (13.0.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deeptrack==0.11.3) (1.15.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deeptrack==0.11.3) (3.3.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deeptrack==0.11.3) (0.37.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deeptrack==0.11.3) (2.7.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deeptrack==0.11.3) (2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deeptrack==0.11.3) (1.13.3)\n",
            "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deeptrack==0.11.3) (2.7.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deeptrack==0.11.3) (1.1.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deeptrack==0.11.3) (0.2.0)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deeptrack==0.11.3) (0.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deeptrack==0.11.3) (3.10.0.2)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deeptrack==0.11.3) (1.0.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deeptrack==0.11.3) (3.1.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deeptrack==0.11.3) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deeptrack==0.11.3) (0.23.1)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deeptrack==0.11.3) (3.17.3)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow->deeptrack==0.11.3) (1.5.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->deeptrack==0.11.3) (57.4.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->deeptrack==0.11.3) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->deeptrack==0.11.3) (3.3.6)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->deeptrack==0.11.3) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->deeptrack==0.11.3) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->deeptrack==0.11.3) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->deeptrack==0.11.3) (1.35.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->deeptrack==0.11.3) (1.0.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow->deeptrack==0.11.3) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow->deeptrack==0.11.3) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow->deeptrack==0.11.3) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow->deeptrack==0.11.3) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow->deeptrack==0.11.3) (4.10.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow->deeptrack==0.11.3) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow->deeptrack==0.11.3) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow->deeptrack==0.11.3) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow->deeptrack==0.11.3) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow->deeptrack==0.11.3) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow->deeptrack==0.11.3) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow->deeptrack==0.11.3) (3.2.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->deeptrack==0.11.3) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons, deeptrack\n",
            "Successfully installed deeptrack-0.11.3 tensorflow-addons-0.15.0\n",
            "Tue Feb  8 09:13:16 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P8    27W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "already_installed = !pip list -v | grep deeptrack\n",
        "if not already_installed:\n",
        "    !pip install deeptrack==0.11.3\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import deeptrack as dt\n",
        "import scipy.io as IO\n",
        "import keras.backend as K\n",
        "import keras.optimizers as optimizers\n",
        "import os\n",
        "from matplotlib import image\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from google.colab import files\n",
        "from cycler import cycler\n",
        "\n",
        "#drive.mount('/content/gdrive')\n",
        "\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T6Pvy7aWMGa9"
      },
      "outputs": [],
      "source": [
        "IMAGE_SIZE = 128\n",
        "\n",
        "particle = dt.MieSphere(\n",
        "    position=lambda: (IMAGE_SIZE/2 + IMAGE_SIZE/50 * np.random.randn(), IMAGE_SIZE/2+IMAGE_SIZE/50*np.random.randn()),\n",
        "    z=lambda: -150 + np.random.random() * 300,\n",
        "    radius=lambda:1e-7 + 3e-7 * np.random.rand() ,\n",
        "    refractive_index=lambda: np.random.uniform(0, 0.3) + 1.37,\n",
        "    L=8,\n",
        "    position_unit=\"pixel\",\n",
        ")\n",
        "\n",
        "HC = dt.HorizontalComa(coefficient=lambda c1: c1, c1=0 + np.random.randn() * 0.05)\n",
        "VC = dt.VerticalComa(coefficient=lambda c2:c2, c2=0 + np.random.randn() * 0.05)\n",
        "\n",
        "def crop(pupil_radius):\n",
        "    def inner(image):\n",
        "        x = np.arange(image.shape[0]) - image.shape[0] / 2\n",
        "        y = np.arange(image.shape[1]) - image.shape[1] / 2\n",
        "        X, Y = np.meshgrid(x, y)\n",
        "        image[X ** 2 + Y ** 2 > pupil_radius ** 2] = 0\n",
        "        return image\n",
        "    return inner\n",
        "CROP = dt.Lambda(crop, pupil_radius=23)\n",
        "\n",
        "optics = dt.Brightfield(\n",
        "    NA=1.3,\n",
        "    resolution=1.13e-6,\n",
        "    wavelength=635e-9,\n",
        "    aperature_angle=53.7 * 2 * np.pi / 360,\n",
        "    polarization_angle=lambda: np.random.rand() * 2 * np.pi,\n",
        "    magnification=10,\n",
        "    output_region=(0, 0, IMAGE_SIZE, IMAGE_SIZE),\n",
        "    padding=(64,) * 4,\n",
        "    return_field=True,\n",
        "    pupil= HC + VC + CROP\n",
        ")\n",
        "\n",
        "real_noise = dt.Gaussian(\n",
        "    mu=0, \n",
        "    sigma=lambda level: np.random.rand() * 0.0,\n",
        ")\n",
        "\n",
        "noise = real_noise + dt.Gaussian(\n",
        "    mu=0, \n",
        "    sigma=lambda real_sigma: real_sigma * 0.0j,\n",
        "    real_sigma=real_noise.sigma\n",
        ")\n",
        "\n",
        "gradient = dt.IlluminationGradient(\n",
        "    gradient=lambda: np.random.randn(2) * 3e-4 * 0,\n",
        ")\n",
        "\n",
        "def func():\n",
        "    def inner(image):\n",
        "        image = (image - 1)\n",
        "        output = np.zeros((*image.shape[:2], 2))\n",
        "        output[..., 0:1] = np.real(image)\n",
        "        output[..., 1:2] = np.imag(image)\n",
        "        return output\n",
        "    return inner\n",
        "\n",
        "\n",
        "complex_to_float = dt.Lambda(func)\n",
        "\n",
        "dataset = optics(particle + noise + gradient) + complex_to_float"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "T00KlEKyQR8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__Bw9X_3MGbH"
      },
      "outputs": [],
      "source": [
        "def get_label(image):\n",
        "    return np.array([image.get_property(\"z\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i3m6A3oqMGbJ"
      },
      "outputs": [],
      "source": [
        "PLOT_IMAGES = False\n",
        "\n",
        "if PLOT_IMAGES:\n",
        "  for i in range(4):\n",
        "      dataset.update()\n",
        "      image_of_particle = dataset.resolve()\n",
        "      position_of_particle = image_of_particle.get_property(\"position\")\n",
        "      \n",
        "      plt.figure(figsize=(10,5))\n",
        "      plt.subplot(1,2,1)\n",
        "      plt.imshow(image_of_particle[:, :, 0], cmap=\"gray\")\n",
        "      plt.scatter(position_of_particle[1], position_of_particle[0], s=120, facecolors='none', edgecolors=\"g\", linewidth=2)\n",
        "      \n",
        "      plt.subplot(1,2,2)\n",
        "      plt.imshow(image_of_particle[:, :, 1], cmap=\"gray\")\n",
        "      plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzLJrwQNMGbL"
      },
      "source": [
        "## 3. Defining the network\n",
        "\n",
        "The network used is a Convolutional network, with a the pixel error as loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MiXlPAiMGbM",
        "outputId": "42619125-cef9-4d23-f1f2-d2af8a488c9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of models to be trained:10\n"
          ]
        }
      ],
      "source": [
        "convlayers = [(32, 64, 128, 128, 128)]\n",
        "denselayers  =[(32, 32)]\n",
        "dropouts = [(0.2, 0.2, 0.2, 0.2, 0.2)]\n",
        "optimizers = [\"adam\"]\n",
        "models = []\n",
        "\n",
        "for _ in range(10):\n",
        "  for conv in convlayers:\n",
        "    for dense in denselayers:\n",
        "      for drop in dropouts:\n",
        "        for optim in optimizers:\n",
        "          model = dt.models.Convolutional(\n",
        "              input_shape=(IMAGE_SIZE, IMAGE_SIZE, 2),\n",
        "              conv_layers_dimensions=conv,\n",
        "              dense_layers_dimensions=dense,\n",
        "              steps_per_pooling=2,\n",
        "              number_of_outputs=1,\n",
        "              dropout=drop,\n",
        "              loss=\"mae\",\n",
        "              optimizer=optim,\n",
        "              dense_block=dt.layers.DenseBlock(activation=\"relu\")\n",
        "          )\n",
        "          models.append(model)\n",
        "          model.totalhistory = {\"val_loss\":[], \"loss\":[]}\n",
        "\n",
        "print(f\"Number of models to be trained:{len(models) }\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qcZ7Q_oj5XwO"
      },
      "outputs": [],
      "source": [
        "def save_progress(h, validation_set, validation_labels, model, plot=True):\n",
        "    model.totalhistory[\"val_loss\"].extend(h.history[\"val_loss\"])\n",
        "    model.totalhistory[\"loss\"].extend(h.history[\"loss\"])            \n",
        "    if plot:\n",
        "        validation_predictions = model.predict(np.array(validation_set))\n",
        "        worst_image_index = np.argmax(np.abs(validation_predictions-np.array(validation_labels)))\n",
        "        worst_selected_image = validation_set[worst_image_index]\n",
        "        worst_actual_z = worst_selected_image.get_property(\"z\")\n",
        "        worst_predicted_z = validation_predictions[worst_image_index,0]\n",
        "\n",
        "        fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(30,8))\n",
        "\n",
        "        ax1.plot(model.totalhistory[\"val_loss\"], 'g', label=\"validation loss\")\n",
        "        ax1.plot(model.totalhistory[\"loss\"], 'b', label=\"training loss\")\n",
        "        ax1.set_xlabel(\"Epoch\")\n",
        "        ax1.set_yscale('log')\n",
        "        ax1.legend()\n",
        "\n",
        "        ax2.plot(validation_predictions, validation_labels, 'r.')\n",
        "        ax2.plot(np.linspace(-150,150),np.linspace(-150,150),'k')\n",
        "        ax2.set_xlabel(\"predicted z\")\n",
        "        ax2.set_ylabel(\"actual z\")\n",
        "\n",
        "        ax3.hist(validation_predictions-np.array(validation_labels), bins=list(np.linspace(-10,10)))\n",
        "        ax3.set_xlabel(\"Pixlar från faktiskt värde\")\n",
        "\n",
        "        ax4.set_title(\"The least well predicted picture from validation_set\")\n",
        "        ax4.set_xlabel(f\"Predicted z: {worst_predicted_z:.2f}, Actual z: {worst_actual_z:.2f}\")\n",
        "        ax4.imshow(worst_selected_image[:,:,0], cmap=\"gray\")\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "def plot_together(models):\n",
        "    cc = (cycler(color=list('bgrcmyk')) +\n",
        "      cycler(linestyle=['-', '--', '-.', ':', '-', '--', '-.']))\n",
        "    \n",
        "    fig, ax = plt.subplots(1,1,figsize=(8,8))\n",
        "    ax.set_prop_cycle(cc)\n",
        "    for i, model in enumerate(models):\n",
        "        ax.plot(model.totalhistory[\"loss\"], label=f\"Model {i}\")\n",
        "        ax.set_xlabel(\"Epochs\")\n",
        "        ax.set_ylabel(\"Training loss\")\n",
        "        ax.legend()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BH1X3QcPMGbO"
      },
      "source": [
        "## 4. Training the network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8glGwu9nMGbP",
        "scrolled": false,
        "outputId": "677fe7e4-dbb9-45b7-d8ba-97da3c3d130f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/deeptrack/optics.py:681: RuntimeWarning: invalid value encountered in true_divide\n",
            "  image = amplitude * image / np.abs(image)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ""
          ]
        }
      ],
      "source": [
        "#checkpoint_path = \"START/firstmodel.ckpt\"\n",
        "#checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "#cp_callback = ModelCheckpoint(filepath=checkpoint_path, save_weights_only=True, verbose=1)\n",
        "\n",
        "TRAIN_MODEL = True\n",
        "\n",
        "validation_set_size = 1024\n",
        "validation_set = [dataset.update().resolve() for _ in range(validation_set_size)]\n",
        "validation_labels = [get_label(image) for image in validation_set]\n",
        "\n",
        "\n",
        "generator = dt.generators.ContinuousGenerator(\n",
        "    dataset,\n",
        "    get_label,\n",
        "    min_data_size=512*5,\n",
        "    max_data_size=512*6,\n",
        "    batch_size=128\n",
        ")\n",
        "\n",
        "with generator:\n",
        "    for i, model in enumerate(models):\n",
        "        h = model.fit(\n",
        "            generator,\n",
        "            validation_data=(\n",
        "                np.array(validation_set), \n",
        "                np.array(validation_labels)\n",
        "            ),\n",
        "            epochs=40,\n",
        "            verbose=0,\n",
        "        )\n",
        "        print(f'Model {i}:', model.optimizer)\n",
        "        save_progress(h, validation_set, validation_labels, model, plot=True)\n",
        "\n",
        "    plot_together(models)\n",
        "    #images_dir = '/content/gdrive/My Drive/Images'\n",
        "    #plt.savefig(f\"{images_dir}/{i}.png\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "one_model = models[0]\n",
        "\n",
        "def mean(img):\n",
        "  outputs = []\n",
        "  for model in models:\n",
        "    guess = model.predict(img)[0]\n",
        "    outputs.append(guess)\n",
        "  big_guess = np.sum(outputs)/len(models)\n",
        "  return big_guess\n",
        "\n",
        "score_one = 0\n",
        "score_mean = 0\n",
        "\n",
        "for i in range(1000):\n",
        "    dataset.update()\n",
        "    img = dataset.resolve()\n",
        "\n",
        "    one_guess = one_model.predict(img)[0]\n",
        "    mean_guess = mean(img)\n",
        "\n",
        "    correct = get_label(img)\n",
        "\n",
        "    one_error = np.abs(correct-one_guess)\n",
        "    mean_error = np.abs(correct-mean_guess)\n",
        "\n",
        "    score_one += one_error\n",
        "    score_mean += mean_error\n",
        "\n",
        "score_one = score_one/1000\n",
        "score_mean = score_mean/1000\n",
        "\n",
        "print(score_one)\n",
        "print(score_mean)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "r1stJ-5kQUpm"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of Kopia av START_20220201.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}